{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('src')\n",
    "\n",
    "img_train = base_path / 'train_images'\n",
    "img_test = base_path / 'test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(base_path / 'train.csv')\n",
    "df_test = pd.read_csv(base_path / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['image'] = df_train['image'].apply(lambda x: img_train / x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate image-files. Rethink if there is a smarter way to handle this (since same picture with different text occurs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(['image'], inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore `image_phash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique images: 28735 of 32412 unique image-files.\n"
     ]
    }
   ],
   "source": [
    "print(f'Unique images: {df_train.image_phash.nunique()} of {df_train.image.nunique()} unique image-files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_label = df_train.groupby(['label_group'])['image_phash'].nunique().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels, that only contain items with the same image_phash: 991\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of labels, that only contain items with the same image_phash: {(df_groupby_label.image_phash < 2).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep labels that have at least 2 items with different image_phash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_labels = df_groupby_label[df_groupby_label.image_phash >= 2].index.tolist()\n",
    "df_train = df_train[df_train['label_group'].isin(keep_labels)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make shure to draw image-files with different phashes, when creating the Siamese dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train['label_group'].unique()\n",
    "y = np.random.choice(x, size = int(len(x)*small_pct), replace = False)\n",
    "df_train = df_train[df_train['label_group'].isin(y)]\n",
    "df_train = df_train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTuple(fastuple):\n",
    "    @classmethod\n",
    "    def create(cls, fns):\n",
    "        return cls(tuple(PILImage.create(f) for f in fns))\n",
    "    \n",
    "    def show(self, ctx = None, **kwargs):\n",
    "        t1, t2 = self\n",
    "        if not isinstance(t1, Tensor) or not isinstance(t2, Tensor) or t1.shape != t2.shape:\n",
    "            return ctx\n",
    "        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n",
    "        \n",
    "        return show_image(torch.cat([t1,line,t2], dim=2), ctx = ctx, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = L(df_train.image.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImageTuple.create((files[0], files[1]))\n",
    "tst = ToTensor()(img)\n",
    "type(tst[0]),type(tst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Resize(224)(img)\n",
    "tst = ToTensor()(img1)\n",
    "tst.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageTupleBlock():\n",
    "    return TransformBlock(type_tfms = ImageTuple.create, batch_tfms = IntToFloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`splits` is a 2-tuple of L-lists. The first element is the list of indices of the training files, the second a list of the indices of the validation files. They are used to mask the files L-lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_label(df):\n",
    "    # L-list of unique labels\n",
    "    labels = L(df.label_group.unique().tolist())\n",
    "    # Randomly split labels\n",
    "    split_labels = RandomSplitter(valid_pct=0.2)(labels)  # Returns 80/20 split of labels\n",
    "\n",
    "    # Mask labels to receive train/val labels\n",
    "    train_labels = labels[split_labels[0]]\n",
    "    validation_labels = labels[split_labels[1]]\n",
    "\n",
    "    # Add colum to mark file as a part of the training/validation set\n",
    "    df['is_valid'] = df_train.label_group.isin(validation_labels)\n",
    "\n",
    "    # Sanity check:\n",
    "    assert((df.groupby(['label_group'])['is_valid'].nunique() > 1).sum() == 0)\n",
    "    \n",
    "    files = L(df['image'].tolist())\n",
    "    train_idx = df[df['is_valid'] == False].index.tolist()\n",
    "    validation_idx = df[df['is_valid'] == True].index.tolist()\n",
    "    \n",
    "    # Sanity check:\n",
    "    assert(set(files[train_idx]) == set(df[df['is_valid'] == False]['image']))\n",
    "    assert(set(files[validation_idx]) == set (df[df['is_valid'] == True]['image']))\n",
    "    \n",
    "    return files, train_labels, validation_labels, train_idx, validation_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files, train_labels, validation_labels, train_split, val_split = split_by_label(df_train)\n",
    "splits = (train_split, val_split)\n",
    "labels = (train_labels,validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the labels 80/20 also results in a ~80/20 file-split\n",
    "n = len(files)\n",
    "print(len(splits[0])/n, len(splits[1])/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_files = [files[splits[i]] for i in range(2)]\n",
    "splits_sets = mapped(set, splits_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(f):\n",
    "    for i,s in enumerate(splits_sets):\n",
    "        if f in s:\n",
    "            return i\n",
    "    raise ValueError(f'File {f} is not presented in any split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f):\n",
    "    return df_train[df_train['image'] == f]['label_group'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, all labels belong to EITHER the training OR the validation set\n",
    "# This does take some while on the whole dataset\n",
    "# assert(set(mapped(label_func,splits_files[0])).intersection(set(mapped(label_func, splits_files[1]))) == set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai tutorial, not suitable for large number of labels! Make use of the dataframe.\n",
    "# splbl2files = [{l: [f for f in s if label_func(f) == l] for l in labels} for s in splits_sets]\n",
    "splbl2files = [(df_train.loc[splits[i]]).groupby(['label_group'])['image'].apply(list).to_dict() for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32412"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue:\n",
    "\n",
    "Some `image_phash`s occure in more than one `label_group`. When creating the dataloaders its decided wether to images are 'the same' on the `label_group`. Given, that the the same image (same `image_phash`) might be mapped as 'not the same' since the `label_group`s are different is a problem.\n",
    "\n",
    "## Solution:\n",
    "Pick one file for every `image_phash`. Remove all `label_group`s that contain less than one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "splbl2files_alt = []\n",
    "\n",
    "df_group_label_phash = df_train.groupby(['label_group','image_phash'])['image'].apply(list).to_frame()\n",
    "\n",
    "df_group_label_phash['nr_images'] = df_group_label_phash['image'].apply(lambda x: len(x))\n",
    "\n",
    "#df_group_label_phash[df_group_label_phash['nr_images'] > 1]\n",
    "\n",
    "df_group_label_phash['chosen_image'] = df_group_label_phash['image'].apply(lambda x: random.choice(x))\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28735"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "valid_files = df_group_label_phash.chosen_image.tolist()\n",
    "\n",
    "print(len(valid_files))\n",
    "\n",
    "df_train.image_phash.nunique()\n",
    "\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28855 28735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "df_test = df_train[df_train['image'].isin(valid_files)]\n",
    "\n",
    "print(len(df_test), df_test.image_phash.nunique())\n",
    "\n",
    "(df_test.groupby(['image_phash'])['label_group'].count() > 1).sum()\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28855 28735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_group</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_phash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84b67e8525cf3f02</th>\n",
       "      <td>[1876943817, 2829310561]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84b67f8525cf3f00</th>\n",
       "      <td>[1876943817, 1424289463, 2829310561]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84eab151bbd44abc</th>\n",
       "      <td>[1417997905, 327189920]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e07e1fffe80e00c</th>\n",
       "      <td>[3128161097, 3888975197]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607293c2fc3bec1</th>\n",
       "      <td>[4009508396, 1942259177]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc57942c26b6e4c8</th>\n",
       "      <td>[185142711, 1127243882]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fcb0701999c74bc3</th>\n",
       "      <td>[1065450055, 4223656537]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe7e898456893163</th>\n",
       "      <td>[196545328, 191984645]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fefa48fa8283a185</th>\n",
       "      <td>[3527837949, 863127146]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff58d047d6049ab2</th>\n",
       "      <td>[3671792044, 4159513302]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           label_group  len\n",
       "image_phash                                                \n",
       "84b67e8525cf3f02              [1876943817, 2829310561]    2\n",
       "84b67f8525cf3f00  [1876943817, 1424289463, 2829310561]    3\n",
       "84eab151bbd44abc               [1417997905, 327189920]    2\n",
       "8e07e1fffe80e00c              [3128161097, 3888975197]    2\n",
       "9607293c2fc3bec1              [4009508396, 1942259177]    2\n",
       "...                                                ...  ...\n",
       "fc57942c26b6e4c8               [185142711, 1127243882]    2\n",
       "fcb0701999c74bc3              [1065450055, 4223656537]    2\n",
       "fe7e898456893163                [196545328, 191984645]    2\n",
       "fefa48fa8283a185               [3527837949, 863127146]    2\n",
       "ff58d047d6049ab2              [3671792044, 4159513302]    2\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "df_test = df_train[df_train['image'].isin(valid_files)]\n",
    "\n",
    "print(len(df_test), df_test.image_phash.nunique())\n",
    "\n",
    "group_image_phash_label = df_test.groupby(['image_phash'])['label_group'].apply(list).to_frame()\n",
    "\n",
    "group_image_phash_label['len'] = group_image_phash_label['label_group'].apply(lambda x: len(x))\n",
    "\n",
    "group_image_phash_label[group_image_phash_label['len'] > 1]\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "label1 = 1417997905\n",
    "label2 = 327189920\n",
    "\n",
    "fx = df_train[df_train['label_group'].isin([label1,label2])].image.tolist()\n",
    "\n",
    "imx = mapped(Image.open,fx)\n",
    "\n",
    "for im in imx:\n",
    "    im.show()\n",
    "\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "ip = 'fcb0701999c74bc3'\n",
    "\n",
    "fs = df_train[df_train['image_phash'] == ip]['image'].tolist()\n",
    "\n",
    "ims = mapped(Image.open,fs)\n",
    "\n",
    "for im in ims:\n",
    "    im.show()\n",
    "\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(items):\n",
    "    def get_split_files(i):\n",
    "        return [j for j,(f1,f2,same) in enumerate(items) if get_split(f1) == i]\n",
    "    return get_split_files(0), get_split_files(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phash(f):\n",
    "    return df_train[df_train['image'] == f]['image_phash'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_other(f):\n",
    "    same = random.random() < 0.5\n",
    "    cls = label_func(f)\n",
    "    split = get_split(f)\n",
    "    if not same:\n",
    "        ## src\n",
    "        # cls = random.choice(L(l for l in labels if 1 != cls))\n",
    "        # make shure to pick a label that is from the same split\n",
    "        cls = random.choice(L(l for l in labels[split] if l != cls))\n",
    "    ## src\n",
    "    #return random.choice(splbl2files[split][cls]),same\n",
    "    # make shure to not pick the input file itself\n",
    "    return random.choice([f2 for f2 in splbl2files[split][cls] if get_phash(f2) != get_phash(f)]), same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############\n",
    "\n",
    "file = files[0]\n",
    "print(file)\n",
    "\n",
    "print(len(files))\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time draw_other(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time cls = label_func(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time split = get_split(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time random.choice(L(l for l in labels[split] if l != cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time random.choice([f2 for f2 in splbl2files[split][cls] if get_phash(f2) != get_phash(file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_phash(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time same = random.random() < 0.5\n",
    "%time cls = label_func(file)\n",
    "%time split = get_split(file)\n",
    "%time if not same: cls = random.choice(L(l for l in labels[split] if l != cls))\n",
    "%time random.choice([f2 for f2 in splbl2files[split][cls] if get_phash(f2) != get_phash(file)]), same\n",
    "\n",
    "%time draw_other(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "##############\n",
    "##############\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuples(files):\n",
    "    return [[f, *draw_other(f)] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(t):\n",
    "    return t[:2]\n",
    "def get_y(t):\n",
    "    return t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese = DataBlock(\n",
    "    blocks = (ImageTupleBlock, CategoryBlock),\n",
    "    get_items = get_tuples,\n",
    "    get_x = get_x,\n",
    "    get_y = get_y,\n",
    "    splitter = splitter,\n",
    "    item_tfms = Resize(224),\n",
    "    batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pct = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time dls = siamese.dataloaders(files, bs = 4)\n",
    "''' small_pct=0.4\n",
    "CPU times: user 7min 25s, sys: 184 ms, total: 7min 25s\n",
    "Wall time: 7min 25s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time dls = siamese.dataloaders(files, bs = 4)\n",
    "''' small_pct=0.3\n",
    "CPU times: user 4min 16s, sys: 119 ms, total: 4min 17s\n",
    "Wall time: 4min 17s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time dls = siamese.dataloaders(files, bs = 4)\n",
    "''' small_pct=0.2\n",
    "CPU times: user 2min 2s, sys: 72.1 ms, total: 2min 2s\n",
    "Wall time: 2min 2s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time dls = siamese.dataloaders(files, bs = 4)\n",
    "''' small_pct=0.1\n",
    "CPU times: user 39.5 s, sys: 20.1 ms, total: 39.5 s\n",
    "Wall time: 39.5 s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_types(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def show_batch(x:ImageTuple, \n",
    "               y, \n",
    "               samples, \n",
    "               ctxs=None, \n",
    "               max_n=6, \n",
    "               nrows=None, \n",
    "               ncols=2, \n",
    "               figsize=None, \n",
    "               **kwargs):\n",
    "    if figsize is None: \n",
    "        figsize = (ncols*6, max_n//ncols * 3)\n",
    "        \n",
    "    if ctxs is None: \n",
    "        ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "        \n",
    "    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    \n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Avoiding ImageTuples with the same phash seems to resolve this.***\n",
    "\n",
    "***Note:*** Some instances that are not the same, can still have the same picture. See if this needs attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twins = []\n",
    "#for i in range(2):\n",
    "#    for label in splbl2files[i].keys():\n",
    "#        remaining = splbl2files[i][label]\n",
    "#        touched = []\n",
    "#        for f1 in remaining:\n",
    "#            touched.append(f1)\n",
    "#            remaining = [g for g in remaining if g not in touched]\n",
    "#            img1 = np.array(Image.open(f1)\n",
    "#                            .convert('L')\n",
    "#                            .resize(((224,224)))\n",
    "#                           ).astype(np.int)\n",
    "#            \n",
    "#            for f2 in remaining:\n",
    "#                img2 = np.array(Image.open(f2)\n",
    "#                            .convert('L')\n",
    "#                            .resize(((224,224)))\n",
    "#                           ).astype(np.int)            \n",
    "#                diff = np.abs(img1 - img2).sum()\n",
    "#                twins.append([f1,f2,diff])\n",
    "#                \n",
    "#list_f1 = [x[0] for x in twins]\n",
    "#list_f2 = [x[1] for x in twins]\n",
    "#list_diff = [x[2] for x in twins]\n",
    "#\n",
    "#d = {'file_1': list_f1, 'file_2': list_f2, 'difference': list_diff}\n",
    "#\n",
    "#df_twins = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1,f2,diff = df_twins.min().tolist()\n",
    "#img1, img2 = Image.open(f1), Image.open(f2)\n",
    "#\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.imshow(img1)\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Module):\n",
    "    def __init__(self, encoder, head):\n",
    "        self.encoder = encoder\n",
    "        self.head = head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ftrs = torch.cat([self.encoder(x[0]), self.encoder(x[1])], dim = 1)\n",
    "        return self.head(ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = model_meta[resnet34]['cut']\n",
    "encoder = create_body(resnet34, cut = cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = create_head(512 * 2, 2, ps=0.5)\n",
    "model = SiameseModel(encoder, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_splitter(model):\n",
    "    return [params(model.encoder), params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls,model,loss_func=loss_func, splitter=siamese_splitter, metrics = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(25, slice(1e-6,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('learner_resnet34_size224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('learner_resnet34_size224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(50, slice(1e-4,1e-2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai2] *",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
